<!DOCTYPE html>
<html>
	<head>
		<link type="text/css" rel="stylesheet" href="stylesheet.css"/>
		<title>Karen Shay West's Home Page</title>
	</head>
	<body>
		<div id="header">
           <!-- <img id="pic"
           src="https://github.com/KarenWest/myPhotosAndVideosForWebSite/KarenShayWestAge50Dec2015_crop.jpeg"/>-->
	          <div id="photo"> <a href="KarenShayWestAgeAlmost52Dec2016.jpg"><img alt=""
            src="KarenShayWestAgeAlmost52Dec2016.jpg" style="border: 0px solid; width: 85px;
            height: 85px;"></a> </div>

            <ul></ul>
			<p id="name">Karen Shay West: Tel: (508) 844-9776</p>
			<a href="mailto:KarenWest15@gmail.com"><p id="email">KarenWest15@gmail.com</p></a>
			<p id="notice"><strong><br>UNDER CONSTRUCTION WEB SITE</strong>,
			  All links now work.  However, the web site is still
			  under construction, since while building it, I
			  learned how better to design it going forward.
			  Future Plans are to shorten web pages if they are 
			  long in description by creating links to other
			  short length web pages within them.  I will add to
			  it over time as well, and I am still learning more
			  about the web languages, so I may tweak it as I do
			  that too. <br><strong>NOTE: LEFT HAND COLUMN
			  LINKS:</strong> Recent and on going online projects
			  and learning in both technical areas and business 
			  humanities.<br><strong>NOTE: MAIN PAGE:</strong> Details 
			  Professional Work Experience, Formal Education (BS
			  and MS) along with recent online learning summaries</p>
	        
	        <ul></ul>

	    <a href="https://drive.google.com/open?id=0B0ao1LZvdelIM2hIdEVGU25iY00"><p id="toprightresume">Link
	    to my resume (CV)!</p></a>
            <ul></ul>
            <a href="http://www.linkedin.com/in/karenshaywest"><p id="toprightlinkedin">Click to go to
            my Linked In site!</p></a>
            <ul></ul>
            <a href="https://github.com/KarenWest"><p id="toprightgithub">Click to go to my Git Hub site!</p></a>
	    <a href='http://www.counter12.com'><p id="centertopcounter">Number
	    of web site visitors since May 26th, 2017!</p></a>
	    <div id="sitevisitorcounter"><img src='http://www.counter12.com/img-yBdW1Cdc49425Zb1-17.gif'
				 border='0'
				 alt='counter'><script type='text/javascript'
							   src='http://www.counter12.com/ad.js?id=yBdW1Cdc49425Zb1'></script></div>


		</div>
		<div class="appliedpythonleft">
		  <ul>
		    <li id="left-01"><a href="index.html">BELOW: List of Recent
		    Learning - CLICK HERE to Go To My Home Page Resume</a></li>
		    <li id="left-02"><a href="currentLearningInProgress.html">
		    Currently focus: web and app development (while job
		    searching), since prior expertise and strengths were in 
		    embedded C programming, with a strong Electrical
		    Engineering educational background, and business
		    humanities.
		    </a></li>
		    <li id="left-03"><a href="androidappsjavaxml.html">Android Apps Java XML</a></li>
		    <li id="left-04"><a href="randdataanalysis.html">R and Data Analysis</a></li>
		    <li id="left-05"><a href="softwareandhardwaresecurity.html">Software
		  And Hardware Security</a></li>
		    <li id="left-06"><a href="appliedpythonexamples.html">Applied Python Examples</a></li>
		    <li id="left-07"><a href="pythonusedforartificialintelligenceonpacman.html">Python Used For Artificial Intelligence On Pacman</a></li>
		    <li id="left-08"><a href="makinganddeployingawebsite.html">Making
	    And Deploying A Website</a></li>
		    <li id="left-09"><a href="matlabandwiresharkandwirelesscommunicationsystems.html">MATLAB
		  and WireShark And Wireless Communication Systems</a></li>
		    <li id="left-10"><a href="gitandgithubandrubyonrailsappsintro.html">Git
	    And Git Hub And Ruby On Rails Apps Intro</a></li>
		    <li id="left-11"><a href="computetechnologyforsmartphone.html">Compute
	    Technology For Smart Phone</a></li>
	            <li id="left-12"><a href="embeddedsystemslabs.html">Embedded Systems Projects</a></li>
		    <li id="left-13"><a href="cshell.html">C Shell Linux
	            Command Interpreter</a></li>
		    <li id="left-14"><a href="cwebserver.html">C Web Server To Physical Computing</a></li>
		    <li id="left-15"><a href="networkprotocols.html">Network Protocols</a></li>
		    <li id="left-16"><a href="databasespatialcomputingsqlmapsandgps.html">Database
	    Spatial Computing SQL maps And GPS</a></li>
		    <li id="left-17"><a href="agilentkeysighttektronixworkshops.html">Agilent
	    Keysight Tektronix Workshops on Their Equipment and Radio Frequencies</a></li>
		    <li id="left-18"><a href="economicsbusinessentrepreneurhumanrightslaws.html">Economics,
		    Business, Entrepreneur, Laws, and Human Rights</a></li>

		  </ul>
		</div>

		<div class="appliedpythonright">

		  <br><h4>Python Project: Markov Decision Processes: policies, rewards and
			values, value iteration and Reinforcement Learning: 
			TD/Q Learning, Exploration and Approximation
			Reinforcement Learning Project: </h4><br>

		  <ul>
		    <li>We implemented Value Iteration and Q-learning, and
		      tested our agents first on GridWorld and later to a 
		      simulated robot controller (Crawler) Pacman.</li><br>
		    <li>Reinforcement learning: an agent that takes actions 
		      on an environment, and the output state and reward from 
		      the action are passed back to the agent that took the
		      action.</li><br>
		    <li>It is a Markov decision process,
		      non-determininsitic.</li><br>
		    <li>You have a set of states with a set of associated
		      actions, and a transition function, a probability of one 
		      of the successor outcomes, a model of the dynamics,
		      along  with the reward of the associated
		      transition.</li><br>
		    <li>Markov means that given the present state, the future
		      and past are independent.</li><br>
		    <li>For decision processes, Markov means action outcomes
		      depend only on the current state, just like search,
		      where the successor function could only depend on the 
		      current state and not its history.</li><br>
		    <li>Deterministic single agent search problems: wanted an 
		      optimal plan, or sequence of actions, start to
		      goal.</li><br>
		    <li>For Markov Decision processes, we want an optimal
		      policy for each state.</li><br>
		    <li>The idea was to create a Pacman that could learn from
		      his environment.</li><br>
		    <li>Once Pacman was done training, he should win very 
		      reliably in test games, since now he is exploiting his 
		      learned policy.</li><br>
		    <li>This worked for small but not medium grids.</li><br>
		    <li>To correct this, we had to implement a q learning
		      agent that learns weights for features of states, where 
		      many states might share the same features.</li><br>
		    <li>Approximate q learning assumes the existence of a 
		      feature function over state and action pairs.</li><br>
		    <li>Approximate-q-agent uses the an extractor to assign a 
		      single feature to every (game state,action)
		      pair.</li><br>
		    <li>Even much larger layouts should be no problem for 
		      approximate-q-learning agent.</li><br>
		    <li>We then had a learning Pacman agent for small, medium
		      or large grids.</li><br>

		  </ul>
		</div>
	</body>
</html>
